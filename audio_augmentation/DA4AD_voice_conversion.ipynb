{"cells":[{"cell_type":"markdown","metadata":{"id":"oQjPCxKnp3MY"},"source":["# Setup\n"]},{"cell_type":"markdown","source":["## Import"],"metadata":{"id":"zRbDU7QtCaXH"}},{"cell_type":"code","source":["%%capture \n","!apt-get install libsox-fmt-all libsox-dev sox > /dev/null\n","!pip install sox\n","!pip install jsonargparse\n"],"metadata":{"id":"IpvC3l-I_Zuz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43Xd82JhpuEF"},"outputs":[],"source":["%%capture \n","import os\n","import gdown\n","\n","import pickle\n","import re\n","\n","import soundfile as sf\n","from scipy.signal import lfilter\n","import librosa\n","\n","import glob\n","import torch\n","import yaml"]},{"cell_type":"markdown","metadata":{"id":"Ep_A5AAZugjv"},"source":["## Gdrive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37416,"status":"ok","timestamp":1648328621493,"user":{"displayName":"Domi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3C7bRk6rNLcUp8Ib99giowLBogh74wvz2nN-qg=s64","userId":"15731206484394126583"},"user_tz":0},"id":"qgl01ejWudXx","outputId":"26df60f0-e3f5-4f90-cb5d-f3fd9b3a0cf4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","PATH_PREFIX = '/content/gdrive'\n","\n","### TO CHANGE ######\n","DIR = f\"/content/gdrive/MyDrive/Path/to/Dementiabank/folder\""]},{"cell_type":"markdown","metadata":{"id":"b4Lr4O6Zp51P"},"source":["## Download models\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":780,"status":"ok","timestamp":1648253219420,"user":{"displayName":"Domi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3C7bRk6rNLcUp8Ib99giowLBogh74wvz2nN-qg=s64","userId":"15731206484394126583"},"user_tz":0},"id":"2VTGepkxqPQI","outputId":"ae3cd034-aaf5-4e1f-cb54-29e859315ebc"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'FragmentVC' already exists and is not an empty directory.\n","\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '/FragmentVC/requirements.txt'\u001b[0m\n"]}],"source":["# downloading the project \n","\n","!git clone https://github.com/yistLin/FragmentVC\n","!pip install -r /FragmentVC/requirements.txt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62679,"status":"ok","timestamp":1648328904946,"user":{"displayName":"Domi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3C7bRk6rNLcUp8Ib99giowLBogh74wvz2nN-qg=s64","userId":"15731206484394126583"},"user_tz":0},"id":"1J0jtRiS4RwJ","outputId":"9b6e147e-8727-45fe-cc8a-a5fed07d6821"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://dl.fbaipublicfiles.com/fairseq/wav2vec/wav2vec_small.pt\n","To: /content/wav2vec_small.pt\n","100% 951M/951M [00:44<00:00, 21.6MB/s]\n","Downloading...\n","From: https://github.com/yistLin/FragmentVC/releases/download/v1.0/fragmentvc.pt\n","To: /content/fragmentvc.pt\n","100% 192M/192M [00:13<00:00, 14.8MB/s]\n","Downloading...\n","From: https://github.com/yistLin/FragmentVC/releases/download/v1.0/vocoder.pt\n","To: /content/vocoder.pt\n","100% 20.5M/20.5M [00:00<00:00, 23.2MB/s]\n"]}],"source":["!gdown https://dl.fbaipublicfiles.com/fairseq/wav2vec/wav2vec_small.pt\n","!gdown https://github.com/yistLin/FragmentVC/releases/download/v1.0/fragmentvc.pt\n","!gdown https://github.com/yistLin/FragmentVC/releases/download/v1.0/vocoder.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PIxUBTVZbPzd"},"outputs":[],"source":["%%capture\n","!pip install -r /content/gdrive/MyDrive/FragmentVC/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRl_irfROruS"},"outputs":[],"source":["%%capture\n","!pip install fairseq\n","!pip install pydub"]},{"cell_type":"markdown","source":["# Voice conversion"],"metadata":{"id":"dKFFpLYgCw6K"}},{"cell_type":"markdown","source":["## Helper functions"],"metadata":{"id":"TsHJVoW3DZcb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5fCjvw8LjJ-"},"outputs":[],"source":["def segment_mp3_tensor(audio, duration, spacing = None, tensor = False):\n","\n","    segments = []\n","    audio_tensor, sr = librosa.load(audio, sr=16000)\n","    audio_len = len(audio_tensor)\n","    start_pt = 0\n","    end_pt = duration*sr\n","    while end_pt < audio_len:\n","        segments.append(audio_tensor[start_pt:end_pt])\n","        if spacing is None: # non-overlapping segments\n","            start_pt += duration*sr\n","            end_pt += duration*sr\n","        else:\n","            start_pt += spacing*sr\n","            end_pt += spacing*sr\n","    return segments\n","\n","def merge_on_id(audio_paths):\n","  full_audio_list = []\n","  for audio in audio_paths:\n","    audio_tensor, sr =  sf.read(audio)\n","    full_audio_list.append(audio_tensor)\n","\n","  full_audio = np.concatenate(full_audio_list)\n","\n","  return full_audio\n"]},{"cell_type":"markdown","source":["## Converting VCTK files from flac to wav"],"metadata":{"id":"s9AN8yr0DbQR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0hmsheZvncWF"},"outputs":[],"source":["import io\n","from pydub import AudioSegment\n","import glob\n","\n","names = glob.glob(f'{dataset_dir}/vctk_4/*.flac')\n","\n","for t in names:\n","  flac = AudioSegment.from_file(t, format='flac')\n","  stream = io.BytesIO()\n","  wav_name = t.replace(\"flac\",\"wav\")\n","  flac.export(wav_name, format='wav')\n","  #data, samplerate = sf.read(t1.replace(\"flac\",'wav'))\n","  y, sr = librosa.load(wav_name,  sr=16000)\n","  sf.write(wav_name, y, sr)\n","\n"]},{"cell_type":"markdown","source":["## Convert Audio files to VCTK voice"],"metadata":{"id":"4PHfq_BME5vW"}},{"cell_type":"markdown","source":["We convert each sample from the Dementiabank to a voice from the VCTK dataset, available [here](https://datashare.ed.ac.uk/handle/10283/3443). "],"metadata":{"id":"sfAdeRxkGp7a"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"G3odu4KpbIyx"},"outputs":[],"source":["def generate_segments_yaml(all_paths,out_path_prefix, samplerate):\n","  lbls = []\n","  ts_list = glob.glob(f'/content/gdrive/MyDrive/PHD/AuthorshipObfuscation/Adress-2020/audio/vctk/*.wav')\n","  dict_file_all = dict()\n","\n","  for file_path in all_paths:\n","    label = file_path.split(\"/\")[-2]\n","    name = os.path.basename(file_path)\n","    ID = name.split(\".\")[0]\n","    dict_file = dict()\n","    \n","    if label in [\"vctk\", 'vctk_2','vctk_3','vctk_4']:\n","      break\n","\n","    lbls.append(label)\n","\n","    out_path = f\"{out_path_prefix}/{ID}\"\n","    if not os.path.exists(out_path):\n","      try:\n","        os.mkdir(f\"{out_path_prefix}/{ID}\")\n","      except OSError:\n","        print (\"Creation of the directory %s failed\" % f\"{out_path_prefix}/{ID}\")\n","    \n","    if not os.path.exists(f'{out_path}/output_seg_0.wav'):\n","\n","      segs = segment_mp3_tensor(file_path, duration = 5)\n","      seg_paths = []\n","\n","      for idx,s in enumerate(segs):\n","        seg_path = f'{out_path}/output_seg_{idx}.wav' \n","        sf.write(f'{out_path}/output_seg_{idx}.wav',s, samplerate)\n","        seg_paths.append(seg_path)\n","\n","      for idx,seg in enumerate(seg_paths): \n","        source = seg\n","        target = ts_list\n","        key = f\"{label}_{ID}_{idx}_x1\"\n","        dict_file[key] = {}\n","        dict_file[key]['source'] = source\n","        dict_file[key]['target'] = list(ts_list) \n","\n","        dict_file_all[key] = {}\n","        dict_file_all[key]['source'] = source\n","        dict_file_all[key]['target'] = list(ts_list) \n","\n","      with open(f'{out_path_prefix}/store_file_{ID}_x1.yaml', 'w+') as file:\n","        documents = yaml.dump(dict_file, file)\n","\n","      with open(f'{out_path_prefix}/store_file.yaml', 'w+') as file:\n","        documents = yaml.dump(dict_file_all, file)\n","\n","\n","def convert_segments(out_path_prefix, sample_rate):\n","  yaml_files = glob.glob(f'{out_path_prefix}/*_x1.yaml')\n","\n","  for yaml_f in yaml_files:\n","    if os.path.basename(yaml_f) == \"store_file.yaml\":\n","      continue\n","    try:\n","      wav_file=os.path.basename(yaml_f).replace('store_file_','cd_').replace('yaml','wav')\n","\n","      wav_file = wav_file.split('_')[0]+\"_\"+wav_file.split('_')[1]+\"_0_x1.wav\"\n","\n","      if not os.path.exists(f'{out_path_prefix}/segments_x1/{wav_file}'):\n","\n","        print(\"fragmentVC for {}\".format(yaml_f))\n","        cmd = f'python /content/gdrive/MyDrive/FragmentVC/convert_batch.py \\\n","          -w \"./wav2vec_small.pt\" \\\n","          --sample_rate \"{sample_rate}\" \\\n","          -v \"./vocoder.pt\" \\\n","          -c \"./fragmentvc.pt\" \\\n","          {yaml_f} \\\n","          {out_path_prefix}/segments_x1'\n","    except subprocess.CalledProcessError as e:\n","        raise RuntimeError(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))\n","\n","\n","def merge_and_save(out_path_prefix, samplerate):\n","  pathlib.Path(f'{out_path_prefix}/Full_aug_samples/x1').mkdir(parents=True, exist_ok=True)\n","  segments_path = f'{out_path_prefix}/segments_x1' \n","  all_segments = glob.glob(f'{segments_path}/*_x1.wav')\n","  \n","  labels_dict = dict()\n","  id_list = [os.path.basename(x).split(\"_\")[1] for x in all_segments]\n","\n","  for x in all_segments:\n","    id_name = os.path.basename(x).split(\"_\")[1]\n","    labels_dict[id_name] =  os.path.basename(x).split(\"_\")[0]\n","\n","  unique_ids = np.unique(id_list)\n","\n","  for speaker in id_list:\n","    id_segs = glob.glob(f'{segments_path}/*_{speaker}_*.wav')\n","    full_sample = merge_on_id(id_segs)\n","    sf.write(f'{out_path_prefix}/Full_aug_samples/x1/{labels_dict[speaker]}_{speaker}.wav',full_sample, samplerate)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4Lq8yt6f83X"},"outputs":[],"source":["adress_path = \"/content/gdrive/MyDrive/PHD/Dementiabank\"\n","samplerate = 16000\n","\n","dataset_dir_cd = '/content/gdrive/MyDrive/PHD/Dementiabank/cd'\n","dataset_dir_cc = '/content/gdrive/MyDrive/PHD/Dementiabank/cc'\n","\n","!mkdir -p /content/gdrive/MyDrive/PHD/Dementiabank/augmented_cd\n","!mkdir -p /content/gdrive/MyDrive/PHD/Dementiabank/augmented_cc\n","\n","cd_paths = glob.glob(f'{dataset_dir_cd}/*.wav')\n","cc_paths = glob.glob(f'{dataset_dir_cc}/*.wav')\n","\n","out_path_prefix_cd = f\"{adress_path}/augmented_cd\"\n","out_path_prefix_cc = f\"{adress_path}/augmented_cc\"\n","\n","generate_segments_yaml(cd_paths,out_path_prefix_cd, samplerate)\n","convert_segments(out_path_prefix_cd, samplerate)\n","merge_and_save(out_path_prefix_cd, samplerate)\n","\n","generate_segments_yaml(cc_paths,out_path_prefix_cc, samplerate)\n","convert_segments(out_path_prefix_cc, samplerate)\n","merge_and_save(out_path_prefix_cc, samplerate)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"DA4AD_voice_conversion.ipynb","provenance":[{"file_id":"1iDBwgFLEKhdv7Izug8y-gNaSRybKpzq9","timestamp":1658176020814},{"file_id":"1_U7pM-Gwcv4Mtp2ZS79d4AjO3J5ISCyL","timestamp":1640643071810}],"toc_visible":true,"authorship_tag":"ABX9TyM759tMFAAPGBQ6tViJ5ICv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}